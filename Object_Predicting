import os
import sys
import argparse
import glob
import time

import cv2
import numpy as np
from ultralytics import YOLO
from scipy.optimize import linear_sum_assignment


# ============================================================
#  SORT TRACKER (FULLY FIXED, NO SHAPE BUGS)
# ============================================================

def iou(bb_test, bb_gt):
    xx1 = np.maximum(bb_test[0], bb_gt[0])
    yy1 = np.maximum(bb_test[1], bb_gt[1])
    xx2 = np.minimum(bb_test[2], bb_gt[2])
    yy2 = np.minimum(bb_test[3], bb_gt[3])
    w = np.maximum(0., xx2 - xx1)
    h = np.maximum(0., yy2 - yy1)
    wh = w * h
    o = wh / ((bb_test[2] - bb_test[0]) * (bb_test[3] - bb_test[1])
              + (bb_gt[2] - bb_gt[0]) * (bb_gt[3] - bb_gt[1]) - wh)
    return o


class KalmanBoxTracker:
    """Internal tracker with a Kalman filter."""

    count = 0

    def __init__(self, bbox):
        # Initialize 8D (x, y, s, r, x', y', s', r')
        self.kf = cv2.KalmanFilter(8, 4)
        self.kf.measurementMatrix = np.eye(4, 8, dtype=np.float32)
        self.kf.transitionMatrix = np.eye(8, dtype=np.float32)
        for i in range(4):
            self.kf.transitionMatrix[i, i + 4] = 1.0

        self.kf.processNoiseCov = np.eye(8, dtype=np.float32) * 0.01
        self.kf.measurementNoiseCov = np.eye(4, dtype=np.float32) * 0.1

        x1, y1, x2, y2 = bbox
        w = x2 - x1
        h = y2 - y1

        cx = x1 + w / 2.
        cy = y1 + h / 2.
        s = w * h
        r = w / (h + 1e-6)

        self.kf.statePre[:4, 0] = np.array([cx, cy, s, r], dtype=np.float32)

        self.time_since_update = 0
        self.id = KalmanBoxTracker.count
        KalmanBoxTracker.count += 1
        self.hit_streak = 0
        self.history = []

    def update(self, bbox):
        """Update with a new detection."""
        self.time_since_update = 0
        self.hit_streak += 1

        x1, y1, x2, y2 = bbox
        w = x2 - x1
        h = y2 - y1

        cx = x1 + w / 2.
        cy = y1 + h / 2.
        s = w * h
        r = w / (h + 1e-6)

        measurement = np.array([[cx], [cy], [s], [r]], dtype=np.float32)
        self.kf.correct(measurement)

    def predict(self):
        """Predict the next location."""
        self.kf.predict()
        self.time_since_update += 1

        cx, cy, s, r = self.kf.statePost[:4, 0]

        w = np.sqrt(s * r)
        h = s / (w + 1e-6)

        x1 = cx - w / 2.
        y1 = cy - h / 2.
        x2 = cx + w / 2.
        y2 = cy + h / 2.

        return np.array([x1, y1, x2, y2])

    def get_state(self):
        return self.predict()


class Sort:
    """SORT: Simple Online and Realtime Tracking"""

    def __init__(self, max_age=30, min_hits=3, iou_threshold=0.3):
        self.max_age = max_age
        self.min_hits = min_hits
        self.iou_threshold = iou_threshold
        self.trackers = []
        self.frame_count = 0

    # ---- FIXED MATCHING (NO SHAPE BUGS) ----
    def _associate_detections_to_trackers(self, detections, trackers, iou_threshold=0.3):

        if len(trackers) == 0:
            return [], list(range(len(detections))), []

        if len(detections) == 0:
            return [], [], list(range(len(trackers)))

        iou_matrix = np.zeros((len(detections), len(trackers)), dtype=np.float32)

        for d, det in enumerate(detections):
            for t, trk in enumerate(trackers):
                try:
                    iou_matrix[d, t] = iou(det[:4], trk)
                except:
                    iou_matrix[d, t] = 0.

        row_ind, col_ind = linear_sum_assignment(-iou_matrix)

        if len(row_ind) > 0:
            matched_indices = np.vstack((row_ind, col_ind)).T
        else:
            matched_indices = np.empty((0, 2), dtype=int)

        unmatched_dets = [d for d in range(len(detections))
                          if matched_indices.size == 0 or d not in matched_indices[:, 0]]

        unmatched_trks = [t for t in range(len(trackers))
                          if matched_indices.size == 0 or t not in matched_indices[:, 1]]

        matches = []
        for d, t in matched_indices:
            if iou_matrix[d, t] < iou_threshold:
                unmatched_dets.append(d)
                unmatched_trks.append(t)
            else:
                matches.append([t, d])

        return matches, unmatched_dets, unmatched_trks

    def update(self, dets):

        self.frame_count += 1

        trks = []
        for t in self.trackers:
            trks.append(t.predict())
        trks = np.array(trks)

        matched, unmatched_dets, unmatched_trks = self._associate_detections_to_trackers(
            dets, trks, self.iou_threshold
        )

        for t_idx, d_idx in matched:
            if t_idx < len(self.trackers) and d_idx < len(dets):
                self.trackers[t_idx].update(dets[d_idx])

        for d_idx in unmatched_dets:
            trk = KalmanBoxTracker(dets[d_idx])
            self.trackers.append(trk)

        i = len(self.trackers)
        for t in reversed(range(i)):
            if self.trackers[t].time_since_update > self.max_age:
                self.trackers.pop(t)

        results = []
        for t in self.trackers:
            if (t.time_since_update < 1):
                results.append(np.append(t.get_state(), t.id))

        return results


# ============================================================
#  YOLO SCRIPT (YOUR ORIGINAL + TRACKING + PREDICTION)
# ============================================================

parser = argparse.ArgumentParser()
parser.add_argument('--model', required=True)
parser.add_argument('--source', required=True)
parser.add_argument('--thresh', default=0.5)
parser.add_argument('--resolution', default=None)
parser.add_argument('--record', action='store_true')
args = parser.parse_args()

model_path = args.model
img_source = args.source
min_thresh = float(args.thresh)
user_res = args.resolution
record = args.record

if not os.path.exists(model_path):
    print("ERROR: Model not found.")
    sys.exit(0)

model = YOLO(model_path)
labels = model.names

img_ext_list = ['.jpg','.jpeg','.png','.bmp','.JPG','.JPEG','.PNG','.BMP']
vid_ext_list = ['.avi','.mov','.mp4','.mkv','.wmv']

if os.path.isdir(img_source):
    source_type = 'folder'
elif os.path.isfile(img_source):
    ext = os.path.splitext(img_source)[1]
    source_type = 'image' if ext in img_ext_list else 'video'
elif 'usb' in img_source:
    source_type = 'usb'
    usb_idx = int(img_source[3:])
elif 'picamera' in img_source:
    source_type = 'picamera'
    picam_idx = int(img_source[8:])
else:
    print("Invalid source.")
    sys.exit(0)

resize = False
if user_res:
    resize = True
    resW, resH = [int(x) for x in user_res.split('x')]

if record:
    if source_type not in ['video','usb']:
        print("Recording only for video/camera.")
        sys.exit(0)
    if not user_res:
        print("Must specify --resolution to record.")
        sys.exit(0)

    recorder = cv2.VideoWriter(
        'demo1.avi',
        cv2.VideoWriter_fourcc(*'MJPG'),
        30,
        (resW, resH)
    )

if source_type == 'image':
    imgs_list = [img_source]
elif source_type == 'folder':
    imgs_list = [f for f in glob.glob(img_source + '/*')
                 if os.path.splitext(f)[1] in img_ext_list]
elif source_type in ['video','usb']:
    cap_arg = img_source if source_type=='video' else usb_idx
    cap = cv2.VideoCapture(cap_arg)
    if resize:
        cap.set(3, resW)
        cap.set(4, resH)
elif source_type == 'picamera':
    from picamera2 import Picamera2
    cap = Picamera2()
    cap.configure(
        cap.create_video_configuration(
            main={"format": 'RGB888', "size": (resW, resH)}
        )
    )
    cap.start()

bbox_colors = [(164,120,87), (68,148,228), (93,97,209), (178,182,133),
               (88,159,106), (96,202,231), (159,124,168), (169,162,241),
               (98,118,150), (172,176,184)]

avg_frame_rate = 0
frame_rate_buffer = []
fps_avg_len = 200
img_count = 0

# ---- SORT TRACKER ----
sort_tracker = Sort()

# For trajectory prediction
previous_centers = {}

while True:

    t_start = time.perf_counter()

    # ---------- LOAD FRAME ----------
    if source_type in ['image','folder']:
        if img_count >= len(imgs_list):
            print("Done.")
            sys.exit(0)
        frame = cv2.imread(imgs_list[img_count])
        img_count += 1

    elif source_type == 'video':
        ret, frame = cap.read()
        if not ret: break

    elif source_type == 'usb':
        ret, frame = cap.read()
        if not ret or frame is None: break

    elif source_type == 'picamera':
        frame = cap.capture_array()
        if frame is None: break

    if resize:
        frame = cv2.resize(frame, (resW, resH))

    # ---------- YOLO INFERENCE ----------
    results = model(frame, verbose=False)
    dets = []

    for box in results[0].boxes:
        conf = box.conf.item()
        if conf < min_thresh: continue

        xyxy = box.xyxy.cpu().numpy().squeeze()
        xmin, ymin, xmax, ymax = xyxy.astype(int)
        dets.append([xmin, ymin, xmax, ymax])

    dets_np = np.array(dets, dtype=float) if len(dets) else np.empty((0,4))

    # ---------- SORT UPDATE ----------
    tracked = sort_tracker.update(dets_np)

    object_count = len(tracked)

    # ---------- DRAW TRACKED OBJECTS ----------
    for trk in tracked:
        x1, y1, x2, y2, track_id = trk
        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])

        color = bbox_colors[int(track_id) % 10]
        cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)

        # --- CENTER DOT ---
        cx = int((x1 + x2)//2)
        cy = int((y1 + y2)//2)
        cv2.circle(frame, (cx, cy), 4, (0,0,255), -1)

        # --- TRAJECTORY PREDICTION ---
        if track_id in previous_centers:
            px, py = previous_centers[track_id]
            vx = cx - px
            vy = cy - py
            pred_x = cx + vx
            pred_y = cy + vy

            cv2.circle(frame, (pred_x, pred_y), 3, (0,255,0), -1)
            cv2.line(frame, (cx,cy), (pred_x,pred_y), (0,255,0), 2)

            size = 15
            cv2.rectangle(frame,
                          (pred_x - size, pred_y - size),
                          (pred_x + size, pred_y + size),
                          (0,255,0), 1)

        previous_centers[track_id] = (cx, cy)

    # ---------- DRAW INFO ----------
    cv2.putText(frame, f'Objects: {object_count}', (10,40),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)

    cv2.imshow("YOLO + SORT + Trajectory", frame)

    if record:
        recorder.write(frame)

    # ---------- KEYBOARD ----------
    key = cv2.waitKey(5 if source_type not in ['image','folder'] else 0)
    if key in [ord('q'), ord('Q')]: break
    if key in [ord('s'), ord('S')]: cv2.waitKey()

    # ---------- FPS ----------
    frame_rate_calc = 1 / (time.perf_counter() - t_start)

    if len(frame_rate_buffer) >= fps_avg_len:
        frame_rate_buffer.pop(0)
    frame_rate_buffer.append(frame_rate_calc)

    avg_frame_rate = np.mean(frame_rate_buffer)

print(f'Average FPS: {avg_frame_rate:.2f}')

if source_type in ['video','usb']:
    cap.release()
if record:
    recorder.release()
cv2.destroyAllWindows()
